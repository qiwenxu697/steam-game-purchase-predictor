{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dff06fd-72b3-450f-a96c-d845baf515d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import Counter\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40900a8a-44bb-45a6-ae7d-89fb8beccb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_user_items(path):\n",
    "    rows = []\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            # parse Python-style dict string into a real dict\n",
    "            user = ast.literal_eval(line)\n",
    "            uid = str(user[\"user_id\"])\n",
    "            for it in user[\"items\"]:\n",
    "                rows.append(\n",
    "                    {\n",
    "                        \"user_id\": uid,\n",
    "                        \"item_id\": str(it[\"item_id\"]),\n",
    "                        \"item_name\": it[\"item_name\"],\n",
    "                        \"playtime_forever\": it.get(\"playtime_forever\", 0),\n",
    "                        \"playtime_2weeks\": it.get(\"playtime_2weeks\", 0),\n",
    "                    }\n",
    "                )\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04f447c-009c-4777-b9b9-5144b98f1a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_items = load_user_items(\"australian_users_items.json\")\n",
    "user_items.head(), user_items.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed4312a-ef03-415d-8ae8-45ef24ded2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_metadata(path):\n",
    "    rows = []\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            obj = ast.literal_eval(line)\n",
    "            rows.append(obj)\n",
    "    return pd.DataFrame(rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a54d41-204d-4b92-a557-d8a05f69608f",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = load_metadata(\"steam_games.json\")\n",
    "metadata.head(), metadata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9cf3a1-4e8e-47d7-9688-65c9cad531d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata[\"id\"] = metadata[\"id\"].astype(str)\n",
    "user_items[\"item_id\"] = user_items[\"item_id\"].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7a0c73-db07-4221-974f-bbd528fb871c",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_users = user_items[\"user_id\"].nunique()\n",
    "num_games = user_items[\"item_id\"].nunique()\n",
    "num_entries = len(user_items)\n",
    "\n",
    "print(\"Number of users:\", num_users)\n",
    "print(\"Number of games:\", num_games)\n",
    "print(\"Number of user–game interactions:\", num_entries)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a42ced0-6805-46cc-aa9b-48a4e23637ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "playtime = user_items[\"playtime_forever\"]\n",
    "playtime_pos = playtime[playtime > 0]\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.hist(np.log1p(playtime_pos), bins=50)\n",
    "plt.xlabel(\"log(1 + playtime_forever) (hours)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Distribution of Playtime (Positive Only)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d89a29-c765-401c-9ef2-2141204f1d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "games_per_user = user_items.groupby(\"user_id\")[\"item_id\"].nunique()\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.hist(games_per_user, bins=50)\n",
    "plt.xlabel(\"Number of games owned per user\")\n",
    "plt.ylabel(\"Number of users\")\n",
    "plt.title(\"User Purchase Frequency\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "games_per_user.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615aa347-22a5-4c0b-baa4-0ba80d9ca006",
   "metadata": {},
   "outputs": [],
   "source": [
    "users_per_game = user_items.groupby(\"item_id\")[\"user_id\"].nunique()\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.hist(np.log1p(users_per_game), bins=50)\n",
    "plt.xlabel(\"log(1 + users per game)\")\n",
    "plt.ylabel(\"Number of games\")\n",
    "plt.title(\"Game Popularity Distribution\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "users_per_game.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d908e8-d110-4084-b5c8-94f60888ce0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prices = metadata[\"price\"].replace(\"Free\", 0)\n",
    "prices = pd.to_numeric(prices, errors=\"coerce\").dropna()\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.hist(prices, bins=50)\n",
    "plt.xlabel(\"Game price ($)\")\n",
    "plt.ylabel(\"Number of games\")\n",
    "plt.title(\"Distribution of Steam Game Prices\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "prices.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ec680e-9cb7-43f1-ac14-975f6a02ec3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_list_column(series):\n",
    "    all_items = Counter()\n",
    "    for x in series.dropna():\n",
    "        for g in x:\n",
    "            all_items[g] += 1\n",
    "    return all_items\n",
    "\n",
    "genre_counts = split_list_column(metadata[\"genres\"])\n",
    "top_genres = genre_counts.most_common(10)\n",
    "\n",
    "labels, counts = zip(*top_genres)\n",
    "plt.figure(figsize=(7,4))\n",
    "plt.bar(labels, counts)\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Top 10 Genres\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "top_genres\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a028d7-8422-4d31-9341-b5795864822f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_counts = split_list_column(metadata[\"tags\"])\n",
    "top_tags = tag_counts.most_common(10)\n",
    "\n",
    "labels_t, counts_t = zip(*top_tags)\n",
    "plt.figure(figsize=(7,4))\n",
    "plt.bar(labels_t, counts_t)\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Top 10 Tags\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "top_tags\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef9bb4d-3409-469e-b420-4450fb9867c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata[\"release_date\"] = pd.to_datetime(metadata[\"release_date\"], errors=\"coerce\")\n",
    "metadata[\"release_year\"] = metadata[\"release_date\"].dt.year\n",
    "\n",
    "print(\"Earliest release year:\", metadata[\"release_year\"].min())\n",
    "print(\"Latest release year:\", metadata[\"release_year\"].max())\n",
    "\n",
    "year_counts = metadata[\"release_year\"].value_counts().sort_index()\n",
    "\n",
    "plt.figure(figsize=(7,4))\n",
    "plt.plot(year_counts.index, year_counts.values, marker=\"o\")\n",
    "plt.xlabel(\"Release year\")\n",
    "plt.ylabel(\"Number of games\")\n",
    "plt.title(\"Number of Games Released per Year\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f788a348-b52b-4455-a64c-90a386268d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = user_items.merge(\n",
    "    metadata,\n",
    "    left_on=\"item_id\",\n",
    "    right_on=\"id\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "df[\"label\"] = 1\n",
    "\n",
    "df.head(), df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80303881-9416-4b1d-9e44-146d2c18f703",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "all_games = set(metadata[\"id\"])\n",
    "\n",
    "neg_rows = []\n",
    "\n",
    "for uid, group in df.groupby(\"user_id\"):\n",
    "    bought = set(group[\"item_id\"])\n",
    "    not_bought = list(all_games - bought)\n",
    "\n",
    "    if len(not_bought) < len(bought):\n",
    "        continue\n",
    "\n",
    "    sampled_negs = random.sample(not_bought, len(bought))\n",
    "\n",
    "    for g in sampled_negs:\n",
    "        neg_rows.append({\n",
    "            \"user_id\": uid,\n",
    "            \"item_id\": g,\n",
    "            \"label\": 0\n",
    "        })\n",
    "\n",
    "neg_df = pd.DataFrame(neg_rows)\n",
    "neg_df = neg_df.merge(metadata, left_on=\"item_id\", right_on=\"id\", how=\"left\")\n",
    "full_df = pd.concat([df, neg_df], ignore_index=True)\n",
    "full_df = full_df.sample(frac=1, random_state=42)  # shuffle\n",
    "\n",
    "user_game_counts = user_items.groupby(\"user_id\")[\"item_id\"].nunique()\n",
    "full_df[\"user_game_count\"] = full_df[\"user_id\"].map(user_game_counts)\n",
    "\n",
    "full_df[\"price\"] = pd.to_numeric(full_df[\"price\"], errors=\"coerce\").fillna(0)\n",
    "\n",
    "list(full_df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61acdd3b-2c94-4575-91ca-2cfb2c4cc225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a random subset of full_df for modeling\n",
    "MODEL_N = 200_000  # try 200k first; increase later if memory allows\n",
    "\n",
    "model_df = full_df.sample(n=MODEL_N, random_state=42).copy()\n",
    "print(\"model_df shape:\", model_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ab839e-b855-4f8a-a821-5a54d0700388",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Clean genres in metadata\n",
    "def to_list_or_empty(x):\n",
    "    if isinstance(x, list):\n",
    "        return x\n",
    "    elif pd.isna(x):\n",
    "        return []\n",
    "    else:\n",
    "        return [x]\n",
    "\n",
    "metadata[\"genres_clean\"] = metadata[\"genres\"].apply(to_list_or_empty)\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "genre_array = mlb.fit_transform(metadata[\"genres_clean\"])\n",
    "\n",
    "genre_cols = [f\"genre_{g}\" for g in mlb.classes_]\n",
    "\n",
    "genre_df = pd.DataFrame(\n",
    "    genre_array,\n",
    "    columns=genre_cols,\n",
    "    index=metadata[\"id\"]\n",
    ")\n",
    "\n",
    "# Make genre columns int8 to save memory\n",
    "genre_df = genre_df.astype(np.int8)\n",
    "\n",
    "# Join onto the *smaller* model_df\n",
    "model_df = model_df.join(genre_df, on=\"item_id\")\n",
    "\n",
    "print(\"model_df shape after genres:\", model_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec27976-a58d-445c-8240-811d28a8c2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_map = {\n",
    "    \"Overwhelmingly Positive\": 5,\n",
    "    \"Very Positive\": 4,\n",
    "    \"Positive\": 3,\n",
    "    \"Mostly Positive\": 2,\n",
    "    \"Mixed\": 1,\n",
    "    \"Negative\": 0,\n",
    "    \"Mostly Negative\": -1,\n",
    "    \"Very Negative\": -2,\n",
    "    \"Overwhelmingly Negative\": -3,\n",
    "}\n",
    "\n",
    "def sentiment_to_score(s):\n",
    "    if pd.isna(s):\n",
    "        return np.nan\n",
    "    s = str(s)\n",
    "    if \"user reviews\" in s:\n",
    "        return np.nan\n",
    "    return sentiment_map.get(s, np.nan)\n",
    "\n",
    "model_df[\"sentiment_score\"] = model_df[\"sentiment\"].apply(sentiment_to_score)\n",
    "model_df[\"sentiment_score\"] = model_df[\"sentiment_score\"].fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a4847b-9c04-4094-ad34-e69817938fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y = model_df[\"label\"]\n",
    "\n",
    "drop_cols = [\n",
    "    \"label\",            # target\n",
    "    \"playtime_forever\", # leakage\n",
    "    \"playtime_2weeks\",  # leakage\n",
    "    \"user_id\",\n",
    "    \"item_id\",\n",
    "    \"id\",\n",
    "    \"item_name\",\n",
    "    \"app_name\",\n",
    "    \"title\",\n",
    "    \"url\",\n",
    "    \"reviews_url\",\n",
    "    \"release_date\",\n",
    "    \"tags\",\n",
    "    \"genres\",\n",
    "    \"publisher\",\n",
    "    \"developer\",\n",
    "    \"specs\",\n",
    "    \"sentiment\",        # raw text; we use sentiment_score\n",
    "]\n",
    "\n",
    "X = model_df.drop(columns=[c for c in drop_cols if c in model_df.columns])\n",
    "\n",
    "# Keep only numeric / bool\n",
    "X = X.select_dtypes(include=[np.number, bool]).fillna(0)\n",
    "\n",
    "print(\"Feature columns (first 20):\", X.columns[:20].tolist())\n",
    "print(\"X shape:\", X.shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(\"Train size:\", X_train.shape, \"Test size:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74a150a-f5a1-4775-af54-0c180467461e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "log_reg_pipeline = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"clf\", LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "log_reg_pipeline.fit(X_train, y_train)\n",
    "\n",
    "y_pred_lr = log_reg_pipeline.predict(X_test)\n",
    "y_prob_lr = log_reg_pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"\\n=== Logistic Regression (Linear) ===\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_lr))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test, y_prob_lr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60710570-d5ee-4ceb-8e07-86e7e867ad79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=12,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "y_prob_rf = rf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"\\n=== Random Forest (Non-linear) ===\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test, y_prob_rf))\n",
    "\n",
    "importances = pd.Series(rf.feature_importances_, index=X_train.columns)\n",
    "print(\"\\nTop 15 RF Features:\")\n",
    "print(importances.sort_values(ascending=False).head(15))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6151cffd-e795-4e82-b329-bbae7ca3f887",
   "metadata": {},
   "outputs": [],
   "source": [
    "#full df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf74bcf3-5a0b-4839-9662-731efe999f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "# ───────────── A. Clean genres in metadata ─────────────\n",
    "\n",
    "def to_list_or_empty(x):\n",
    "    # metadata[\"genres\"] is usually list-like; some entries may be NaN or strings\n",
    "    if isinstance(x, list):\n",
    "        return x\n",
    "    elif pd.isna(x):\n",
    "        return []\n",
    "    else:\n",
    "        # if it's a string like \"Action\", wrap in list\n",
    "        return [x]\n",
    "\n",
    "metadata[\"genres_clean\"] = metadata[\"genres\"].apply(to_list_or_empty)\n",
    "\n",
    "# ───────────── B. Fit MultiLabelBinarizer on metadata genres ─────────────\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "genre_array = mlb.fit_transform(metadata[\"genres_clean\"])\n",
    "\n",
    "# Prefix columns with \"genre_\" to keep things clear\n",
    "genre_cols = [f\"genre_{g}\" for g in mlb.classes_]\n",
    "\n",
    "genre_df = pd.DataFrame(\n",
    "    genre_array,\n",
    "    columns=genre_cols,\n",
    "    index=metadata[\"id\"]  # index by app id\n",
    ")\n",
    "\n",
    "# ───────────── C. Join genre one-hot features into full_df ─────────────\n",
    "\n",
    "# full_df has \"item_id\" which matches metadata[\"id\"]\n",
    "full_df = full_df.join(genre_df, on=\"item_id\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c923ce-3aa7-4298-adf1-33f91d32832b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert sentiment -> numeric score\n",
    "\n",
    "sentiment_map = {\n",
    "    \"Overwhelmingly Positive\": 5,\n",
    "    \"Very Positive\": 4,\n",
    "    \"Positive\": 3,\n",
    "    \"Mostly Positive\": 2,\n",
    "    \"Mixed\": 1,\n",
    "    \"Negative\": 0,\n",
    "    \"Mostly Negative\": -1,\n",
    "    \"Very Negative\": -2,\n",
    "    \"Overwhelmingly Negative\": -3,\n",
    "}\n",
    "\n",
    "def sentiment_to_score(s):\n",
    "    if pd.isna(s):\n",
    "        return np.nan\n",
    "    s = str(s)\n",
    "    # Entries like \"8 user reviews\", too few reviews, treat as missing\n",
    "    if \"user reviews\" in s:\n",
    "        return np.nan\n",
    "    return sentiment_map.get(s, np.nan)\n",
    "\n",
    "full_df[\"sentiment_score\"] = full_df[\"sentiment\"].apply(sentiment_to_score)\n",
    "\n",
    "# Fill missing sentiment with 0 (neutral-ish)\n",
    "full_df[\"sentiment_score\"] = full_df[\"sentiment_score\"].fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9110ab58-cbe8-42d9-a2bd-8d2fcf67b407",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Build feature matrix X and target y\n",
    "\n",
    "y = full_df[\"label\"]\n",
    "\n",
    "# Columns we DO NOT want as features\n",
    "drop_cols = [\n",
    "    \"label\",            # target\n",
    "    \"playtime_forever\", # post-purchase info (leaks label)\n",
    "    \"playtime_2weeks\",  # post-purchase info\n",
    "    \"user_id\",          # ids\n",
    "    \"item_id\",\n",
    "    \"id\",\n",
    "    \"item_name\",\n",
    "    \"app_name\",\n",
    "    \"title\",\n",
    "    \"url\",\n",
    "    \"reviews_url\",\n",
    "    \"release_date\",\n",
    "    \"tags\",\n",
    "    \"genres\",           # raw list/text\n",
    "    \"publisher\",\n",
    "    \"developer\",\n",
    "    \"specs\",\n",
    "    \"sentiment\",        # raw text; we use sentiment_score instead\n",
    "]\n",
    "\n",
    "X = full_df.drop(columns=[c for c in drop_cols if c in full_df.columns])\n",
    "\n",
    "# Keep only numeric and boolean columns\n",
    "X = X.select_dtypes(include=[np.number, bool]).fillna(0)\n",
    "\n",
    "# Train/test split (stratified to preserve class balance)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a709f12c-2475-4c60-b173-bc83f2890806",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear model — Logistic Regression\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "log_reg_pipeline = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"clf\", LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "log_reg_pipeline.fit(X_train, y_train)\n",
    "\n",
    "y_pred_lr = log_reg_pipeline.predict(X_test)\n",
    "y_prob_lr = log_reg_pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"\\n=== Logistic Regression (Linear Model) ===\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_lr))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test, y_prob_lr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fb2bfa-6fb1-427e-802c-4b24e7af7aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-linear model — Random Forest\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=12,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "y_prob_rf = rf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"\\n=== Random Forest (Non-linear Model) ===\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test, y_prob_rf))\n",
    "\n",
    "# Feature importances\n",
    "importances = pd.Series(rf.feature_importances_, index=X_train.columns)\n",
    "print(\"\\nTop 15 Random Forest Features:\")\n",
    "print(importances.sort_values(ascending=False).head(15))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1133b3b4-2ea3-4e35-9d52-8948141fd67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "# ───────────── 1. Build X, y from full_df ─────────────\n",
    "\n",
    "# Columns that must NOT be used as features\n",
    "leak_cols = [\n",
    "    \"label\",            # target\n",
    "    \"playtime_forever\", # post-purchase info\n",
    "    \"playtime_2weeks\",  # post-purchase info\n",
    "    \"item_id\",          # IDs, not features\n",
    "    \"user_id\",\n",
    "    \"item_name\",\n",
    "    \"app_name\",\n",
    "    \"title\",\n",
    "    \"url\",\n",
    "    \"release_date\",\n",
    "    \"tags\",\n",
    "    \"publisher\",\n",
    "    \"developer\",\n",
    "    \"reviews_url\",\n",
    "    \"specs\",\n",
    "    \"genres\",           # raw list/text, not encoded\n",
    "    \"id\"                # duplicate of item_id from metadata\n",
    "]\n",
    "\n",
    "y = full_df[\"label\"]\n",
    "\n",
    "X = full_df.drop(columns=[c for c in leak_cols if c in full_df.columns])\n",
    "X = X.select_dtypes(include=[np.number, bool]).fillna(0)\n",
    "\n",
    "print(\"Feature columns used:\", list(X.columns))\n",
    "print(\"X shape:\", X.shape)\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2285e465-de5c-4c9a-81d1-2787c9ac47ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ───────────── 2. Linear model: Logistic Regression ─────────────\n",
    "\n",
    "log_reg_pipeline = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"clf\", LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "log_reg_pipeline.fit(X_train, y_train)\n",
    "\n",
    "y_pred_lr = log_reg_pipeline.predict(X_test)\n",
    "y_prob_lr = log_reg_pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"\\n=== Logistic Regression (Linear Model) ===\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_lr))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test, y_prob_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091995ae-05e2-449c-9eda-8a9cb7e7e25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ───────────── 3. Non-linear model: Random Forest ─────────────\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=10,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "y_prob_rf = rf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"\\n=== Random Forest (Non-linear Model) ===\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test, y_prob_rf))\n",
    "\n",
    "# Top feature importances for RF\n",
    "importances = pd.Series(rf.feature_importances_, index=X_train.columns)\n",
    "print(\"\\nTop Random Forest Features:\")\n",
    "print(importances.sort_values(ascending=False).head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02efc9b1-8aed-4e7d-96d3-ea4d3ce17be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f58d794-1430-421a-9303-c9fe88abf1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.value_counts(normalize=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee600fe0-d910-492a-b277-6c8fefbed373",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.corrwith(y).sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3312a966-37e4-4072-bccb-73843013fe71",
   "metadata": {},
   "outputs": [],
   "source": [
    "leak_cols = [\n",
    "    \"label\",              \n",
    "    \"popularity\" ,\n",
    "    \"playtime_forever\",    \n",
    "    \"playtime_2weeks\",    \n",
    "    \"item_id\",             \n",
    "    \"user_id\"             \n",
    "]\n",
    "X_noleak = X.drop(columns=[c for c in leaky_cols if c in X.columns])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_noleak, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_prob = model.predict_proba(X_test)[:,1]\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test, y_prob))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe93fcf-e27d-40c3-91c8-43425bed7267",
   "metadata": {},
   "outputs": [],
   "source": [
    "leak_cols = [\n",
    "    \"label\",               # ← direct leakage\n",
    "    \"playtime_forever\",    # ← post-purchase information\n",
    "    \"playtime_2weeks\",     # ← post-purchase information\n",
    "    \"item_id\",             # ← ID only, no predictive meaning\n",
    "    \"user_id\"              # ← ID only\n",
    "]\n",
    "\n",
    "X_clean = full_df.drop(columns=[c for c in leak_cols if c in full_df.columns])\n",
    "y = full_df[\"label\"]\n",
    "\n",
    "# Keep only numeric columns\n",
    "import numpy as np\n",
    "X_clean = X_clean.select_dtypes(include=[np.number, bool]).fillna(0)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_clean, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_prob = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test, y_prob))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0864d18b-978c-48c5-baf0-03c6407d13bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "leak_cols = [\n",
    "    \"label\",               # ← direct leakage\n",
    "    \"playtime_forever\",    # ← post-purchase information\n",
    "    \"playtime_2weeks\",     # ← post-purchase information\n",
    "    \"item_id\",             # ← ID only, no predictive meaning\n",
    "    \"user_id\"              # ← ID only\n",
    "]\n",
    "\n",
    "X_clean = full_df.drop(columns=[c for c in leak_cols if c in full_df.columns])\n",
    "y = full_df[\"label\"]\n",
    "\n",
    "# Keep only numeric columns\n",
    "import numpy as np\n",
    "X_clean = X_clean.select_dtypes(include=[np.number, bool]).fillna(0)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_clean, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=10,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "y_prob_rf = rf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"Random Forest Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
    "print(\"Random Forest ROC AUC:\", roc_auc_score(y_test, y_prob_rf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27dd775a-2afb-4a48-9439-42d96b823b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "importances = pd.Series(rf.feature_importances_, index=X_train.columns)\n",
    "importances.sort_values(ascending=False).head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194bff56-50f6-48c4-aa00-64f4cd417fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "def to_list_or_empty(x):\n",
    "    if isinstance(x, list):\n",
    "        return x\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "# Work on metadata first\n",
    "metadata[\"genres_clean\"] = metadata[\"genres\"].apply(to_list_or_empty)\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "genre_array = mlb.fit_transform(metadata[\"genres_clean\"])\n",
    "\n",
    "genre_df = pd.DataFrame(\n",
    "    genre_array,\n",
    "    columns=mlb.classes_,\n",
    "    index=metadata[\"id\"]\n",
    ")\n",
    "\n",
    "full_df = full_df.join(genre_df, on=\"item_id\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c5e4f9-2504-4f08-97f4-f79511e3fa8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "leak_cols = [\"label\", \"playtime_forever\", \"playtime_2weeks\", \"item_id\", \"user_id\"]\n",
    "\n",
    "X_clean = full_df.drop(columns=[c for c in leak_cols if c in full_df.columns])\n",
    "X_clean = X_clean.select_dtypes(include=[np.number, bool]).fillna(0)\n",
    "\n",
    "y = full_df[\"label\"]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_clean, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=10,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "rf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9221678d-f437-4ad2-a536-8fb901b144eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = pd.Series(rf.feature_importances_, index=X_train.columns)\n",
    "importances.sort_values(ascending=False).head(15)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
